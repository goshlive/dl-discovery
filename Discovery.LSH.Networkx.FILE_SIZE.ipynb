{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e4bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_total_file_size(root_dir, file_type, max_file_size, min_columns):\n",
    "    total_file = 0\n",
    "    total_size = 0\n",
    "    min_size = np.inf\n",
    "    max_size = 0\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            # Get the full file path\n",
    "            file_path = os.path.join(foldername, filename)\n",
    "            \n",
    "            if filename.endswith(file_type):                \n",
    "                if min_columns > 0:\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        if df.shape[1] > min_columns:\n",
    "                            size = os.path.getsize(file_path)\n",
    "                            total_size += size\n",
    "                            total_file += 1\n",
    "                            if (size < min_size):\n",
    "                                min_size = size\n",
    "                            if (size > max_size):\n",
    "                                max_size = size\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        pass  # Handle empty files\n",
    "                else:\n",
    "                    excluded = False\n",
    "                    if os.path.getsize(file_path) > max_file_size:\n",
    "                        excluded = True\n",
    "                    if not excluded:\n",
    "                        size = os.path.getsize(file_path)\n",
    "                        total_size += size\n",
    "                        total_file += 1\n",
    "                        if (size < min_size):\n",
    "                            min_size = size\n",
    "                        if (size > max_size):\n",
    "                            max_size = size\n",
    "\n",
    "    print(f\" Dir: {root_directory}, Type:{file_type}, Min. Cols: {min_columns}, Max. Included File Size: \\\n",
    "    {max_file_size_bytes}: Min. Size: {min_size}, Max. Size: {max_size}, Total File: {total_file}, Total Size: {total_size}, Avg. File Size: {total_size/total_file}\")\n",
    "    return total_size, min_size, max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c10f0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/domain_net/table_union_search/csvfiles, Type:.csv, Min. Cols: 0, Max. Included File Size:     inf: Min. Size: 7724, Max. Size: 5812274, Total File: 1327, Total Size: 1067674587\n"
     ]
    }
   ],
   "source": [
    "# DOMAIN_NET\n",
    "root_directory = 'data/domain_net/table_union_search/csvfiles'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = np.inf\n",
    "min_columns = 0\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19826bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/sqlite, Type:.csv, Min. Cols: 1, Max. Included File Size:     inf: Min. Size: 20474, Max. Size: 5840261, Total File: 1430, Total Size: 1170538633\n"
     ]
    }
   ],
   "source": [
    "# SQLITE\n",
    "root_directory = 'data/sqlite'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = np.inf\n",
    "min_columns = 1\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de70dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/ics_uci/all/dataset, Type:.csv, Min. Cols: 0, Max. Included File Size:     inf: Min. Size: 1794, Max. Size: 940590, Total File: 114, Total Size: 20885187\n"
     ]
    }
   ],
   "source": [
    "# ICS-UCI\n",
    "root_directory = 'data/ics_uci/all/dataset'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = np.inf\n",
    "min_columns = 0\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09fea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/romulo/data-lakes/clustering/Steller-Sea-Lions, Type:.csv, Min. Cols: 0, Max. Included File Size:     inf: Min. Size: 3008, Max. Size: 108302076, Total File: 41, Total Size: 270878887, Avg. File Size: 6606802.12195122\n"
     ]
    }
   ],
   "source": [
    "# Stellar Sea Lions\n",
    "root_directory = 'data/romulo/data-lakes/clustering/Steller-Sea-Lions'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = np.inf\n",
    "min_columns = 0\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfb5aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/romulo/data-lakes/clustering/Tax-Filers, Type:.csv, Min. Cols: 0, Max. Included File Size:     inf: Min. Size: 228398, Max. Size: 21075481, Total File: 531, Total Size: 1012599609, Avg. File Size: 1906967.2485875706\n"
     ]
    }
   ],
   "source": [
    "# Stellar Sea Lions\n",
    "root_directory = 'data/romulo/data-lakes/clustering/Tax-Filers'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = np.inf\n",
    "min_columns = 0\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de16d140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/romulo/data-lakes/clustering, Type:.csv, Min. Cols: 0, Max. Included File Size:     1000000: Min. Size: 134, Max. Size: 998445, Total File: 1268, Total Size: 523208286\n"
     ]
    }
   ],
   "source": [
    "# ROMULO\n",
    "root_directory = 'data/romulo/data-lakes/clustering'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = 1000000\n",
    "min_columns = 0\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29bb9562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dir: data/romulo/data-lakes/clustering, Type:.csv, Min. Cols: 0, Max. Included File Size:     inf: Min. Size: 134, Max. Size: 970081352, Total File: 2560, Total Size: 9349744293\n"
     ]
    }
   ],
   "source": [
    "# ROMULO-ALL\n",
    "root_directory = 'data/romulo/data-lakes/clustering'\n",
    "file_type = '.csv'\n",
    "max_file_size_bytes = np.inf\n",
    "min_columns = 0\n",
    "total_size = filter_and_total_file_size(root_directory, file_type, max_file_size_bytes, min_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
